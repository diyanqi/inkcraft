// utils/generate-continuation.ts
import { generateText, streamText } from 'ai';
import { parse } from 'best-effort-json-parser';
// Import the defined models
import { openai, deepseek, siliconflow, gpt } from './models';

// Helper type for the enqueue function
type EnqueueFunction = (data: any) => void;

// Define the expected top-level scoring categories from the prompt (used by generateScore)
const SCORING_CATEGORIES = [
  "å†…å®¹ä¸åŸæ–‡èæ´½åº¦",
  "æƒ…èŠ‚åˆç†æ€§ä¸å®Œæ•´æ€§",
  "è¯æ±‡ä¸°å¯Œæ€§",
  "è¯­æ³•å‡†ç¡®æ€§",
  "å¥å¼å¤šæ ·æ€§",
  "è¡”æ¥ä¸è¿è´¯æ€§",
  "åˆ›æ–°æ€§ä¸é€»è¾‘æ€§",
  "æ–‡ä½“ä¸äººç§°ä¸€è‡´æ€§",
  "è‹±è¯­æ–‡å­¦ç´ å…»ä¸æ•™å¸ˆä¸»è§‚è¯„ä»·"
];

/**
 * Generates the score and detailed breakdown for the essay continuation.
 * Streams the raw AI response to the console and sends progress updates for scoring categories.
 * @param originalText The original text prompt.
 * @param essayText The user's essay continuation text.
 * @param tone The tone parameter.
 * @param model The model parameter.
 * @param enqueue Function to send progress updates via the stream.
 * @returns An object containing the calculated score and the detailed content string.
 */
export async function generateScore(
  originalText: string,
  essayText: string,
  tone: string,
  model: string,
  enqueue: EnqueueFunction
): Promise<{ score: number, content: string }> {
  enqueue({ type: 'progress', message: 'æ­£åœ¨ç”Ÿæˆè¯„åˆ†...' });
  console.log("Initiating score generation..."); // Console log start

  let content = `# 1. é¢˜ç›®\n${originalText}\n# 2. æˆ‘çš„ç»­å†™\n${essayText}\n`;
  let fullResponseText = ''; // Accumulator for the full AI response text
  const reportedCategories = new Set<string>(); // Track categories already reported via enqueue

  try {
    // Use the specific model defined in the original logic
    const aiModel = (
      model === 'llama' ? openai('@cf/meta/llama-4-scout-17b-16e-instruct') :
        model === 'deepseek' ? deepseek('deepseek-chat') :
          model === 'qwen' ? siliconflow('Qwen/Qwen3-8B') :
            model === 'glm' ? siliconflow('THUDM/GLM-Z1-9B-0414') :
              model === 'gpt4' ? siliconflow('gpt-3.5-turbo') :
                openai('@cf/qwen/qwen1.5-14b-chat-awq') // Default model
    );

    const tonePrompt = (
      tone === 'serious' ? "ç‰¹åˆ«è¦æ±‚ï¼šä½ çš„è¯„è®ºæ‰¹æ”¹è¯­æ°”éœ€è¦ä¸€æœ¬æ­£ç»ï¼Œåƒä¸€ä¸ªç»éªŒä¸°å¯Œè€Œä¸¥å‰çš„è€å¸ˆã€‚" :
        tone === 'humorous' ? "ç‰¹åˆ«è¦æ±‚ï¼šä½ çš„è¯„è®ºæ‰¹æ”¹è¯­æ°”éœ€è¦å¹½é»˜é£è¶£ï¼Œå¯ä»¥ç”¨ä¸Šç½‘ç»œæ¢—ï¼Œå¯ä»¥å¤šç”¨emojiè¡¨æƒ…åŒ…ï¼Œå¯ä»¥å¤šæç¬‘ã€‚" :
          tone === 'sharp' ? "ç‰¹åˆ«è¦æ±‚ï¼šä½ çš„è¯„è®ºæ‰¹æ”¹è¯­æ°”éœ€è¦å°–é”ã€é”è¯„ã€ä¸€é’ˆè§è¡€ã€‚" :
            ""
    );

    console.log("--- Streaming AI response for score ---"); // Marker for console output

    // Call streamText and iterate over the response stream
    const streamResult = await streamText({
      model: aiModel,
      messages: [
        {
          role: 'system',
          content: `"ä½ æ˜¯ä¸€ä¸ªé«˜è€ƒè‹±è¯­è¯»åç»­å†™çš„é˜…å·è€å¸ˆï¼Œç°åœ¨æœ‰ä¸€ä¸ªé«˜è€ƒè‹±è¯­è¯»åç»­å†™ä½œæ–‡é¢˜ç›®å’Œä¸€ç¯‡å¾…æ‰¹æ”¹ç»­å†™ä½œæ–‡ï¼Œéœ€è¦ä½ å¯¹è¿™ç¯‡å¾…æ‰¹æ”¹ä½œæ–‡è¿›è¡Œè¯„åˆ†ã€‚
è¦æ±‚ï¼š
1ï¼‰è¯·è®¤çœŸé˜…è¯»ä½œæ–‡æ‰¹æ”¹è¦æ±‚å’Œä½œæ–‡é¢˜ç›®ï¼Œå¯¹è¿™ç¯‡å¾…æ‰¹æ”¹ä½œæ–‡è¿›è¡Œå…¬æ­£ä¸¥æ ¼çš„æ‰¹æ”¹å’Œæ‰“åˆ†ï¼›
2ï¼‰è¯„åˆ†ä¸€å®šè¦ä¸¥æ ¼ï¼Œå®äº‹æ±‚æ˜¯ï¼Œå¥½çš„ç»™é«˜åˆ†ï¼Œå·®çš„ç»™ä½åˆ†ã€‚
3ï¼‰æœ€åè¿”å›å†…å®¹è¦ä¸¥æ ¼æŒ‰ç…§æœ€åçš„è¾“å‡ºæ ¼å¼ã€‚

ä¸€ã€ä½œæ–‡æ‰¹æ”¹è¦æ±‚
  ä¸èƒ½è½»æ˜“éšä¾¿ç»™å‡ºé«˜åˆ†ï¼Œæ›´ä¸èƒ½ç»™å‡ºæ»¡åˆ†ã€‚
  è¦ä¸¥æ ¼æ‰¹æ”¹ï¼Œæ¯ä¸€å¤„è¯„åˆ†éƒ½è¦åœ¨ç”¨æˆ·çš„ä½œæ–‡ä¸­æ‰¾åˆ°è¯æ®ã€‚
  æ¯ä¸ªå­é¡¹éœ€å…ˆè¯´æ˜è¯„åˆ†ç†ç”±å†ç»™å‡ºå…·ä½“åˆ†æ•°ï¼š
1. å†…å®¹ä¸åŸæ–‡èæ´½åº¦ï¼ˆ15åˆ†ï¼‰
â€¢ 1.1 æƒ…èŠ‚è¿è´¯æ€§ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šæ®µé¦–ç”¨æ—¶é—´/åŠ¨ä½œ/ç¯å¢ƒæå†™æ— ç¼è¡”æ¥åŸæ–‡ï¼ˆå¦‚åŸæ–‡ç»“å°¾"midnight"â†’ç»­å†™"At dawn..."ï¼‰
  â—¦ 2åˆ†ï¼šè¡”æ¥åŸºæœ¬åˆç†ä½†ç¼ºä¹è¿‡æ¸¡è¯ï¼ˆç›´æ¥è·³è½¬"Two days later..."ï¼‰
  â—¦ 0åˆ†ï¼šæƒ…èŠ‚æ–­è£‚ï¼ˆå¦‚åŸæ–‡ç´§å¼ åœºæ™¯çªè½¬æ¬¢ä¹æ´¾å¯¹ï¼‰
â€¢ 1.2 äººç‰©ä¸€è‡´æ€§ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šè¨€è¡Œç¬¦åˆåŸæ–‡è®¾å®šï¼ˆå¦‚æ‡¦å¼±è§’è‰²ä¿æŒè°¨æ…ï¼‰
  â—¦ 2åˆ†ï¼šæ¬¡è¦äººç‰©æ€§æ ¼è½»å¾®åå·®ï¼ˆå¦‚æœ‹å‹ä»å®‰é™å˜ä¸ºå¥è°ˆï¼‰
  â—¦ 0åˆ†ï¼šä¸»è§’è¡Œä¸ºä¸¥é‡çŸ›ç›¾ï¼ˆå–„è‰¯è€…æ— æ•…ä¼¤å®³ä»–äººï¼‰
â€¢ 1.3 ä¸»é¢˜å¥‘åˆåº¦ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šæ·±åŒ–åŸæ–‡ä¸»é¢˜ï¼ˆå¦‚"ç¯ä¿"â†’ç»­å†™æ¸…ç†æ±¡æŸ“ï¼‰
  â—¦ 2åˆ†ï¼šä¿æŒä¸»é¢˜ä½†ç¼ºä¹å‘å±•ï¼ˆä»…é‡å¤åŸæ–‡å†…å®¹ï¼‰
  â—¦ 0åˆ†ï¼šåç¦»æ ¸å¿ƒä¸»é¢˜ï¼ˆå¦‚"å‹è°Š"æ•…äº‹çªè½¬å•†ä¸šç«äº‰ï¼‰
2. æƒ…èŠ‚åˆç†æ€§ä¸å®Œæ•´æ€§ï¼ˆ15åˆ†ï¼‰
â€¢ 2.1 å†²çªè§£å†³ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šç”¨ä¼ç¬”è§£å†³çŸ›ç›¾ï¼ˆå¦‚ç”¨å‰æ–‡"åœ°å›¾"è„±å›°ï¼‰
  â—¦ 2åˆ†ï¼šè§£å†³åˆç†ä½†ç¼ºä¹é“ºå«ï¼ˆçªç„¶å‡ºç°æ•‘æ´é˜Ÿï¼‰
  â—¦ 0åˆ†ï¼šæœªè§£å†³å†²çªæˆ–æœºæ¢°é™ç¥ï¼ˆå¤–æ˜Ÿäººæ•‘åœºï¼‰
â€¢ 2.2 ç¬¦åˆå¸¸è¯†ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šç¬¦åˆç‰©ç†/ç¤¾ä¼šè§„åˆ™ï¼ˆé›¨å¤©ç”¨å¡‘æ–™å¸ƒç”Ÿç«ï¼‰
  â—¦ 2åˆ†ï¼šè½»å¾®ç‘•ç–µï¼ˆæ£®æ—ä¸­è½»æ˜“æ‰¾åˆ°è¯å“ï¼‰
  â—¦ 0åˆ†ï¼šä¸¥é‡è¿èƒŒå¸¸è¯†ï¼ˆå¾’æ‰‹å‡»é€€ç‹¼ç¾¤ï¼‰
â€¢ 2.3 ç§¯æç»“å±€ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šè‡ªç„¶ä¼ é€’æ­£èƒ½é‡ï¼ˆäº’åŠ©è„±å›°åå»ºç«‹å‹è°Šï¼‰
  â—¦ 2åˆ†ï¼šç»“å±€ç§¯æä½†çªå…€ï¼ˆç›´æ¥é™ˆè¿°"ä»–ä»¬å¹¸ç¦äº†"ï¼‰
  â—¦ 0åˆ†ï¼šæ¶ˆæç»“å±€ï¼ˆä¸»è§’æ”¾å¼ƒæˆ–æ­»äº¡ï¼‰
3. è¯æ±‡ä¸°å¯Œæ€§ï¼ˆ10åˆ†ï¼‰
â€¢ 3.1 è¯æ±‡å¤šæ ·æ€§ï¼ˆ3åˆ†ï¼‰
  â—¦ 3åˆ†ï¼šåŒä¹‰è¯æ›¿æ¢â‰¥5å¤„ï¼ˆ"said"â†’whispered/exclaimedï¼‰
  â—¦ 1åˆ†ï¼šæ›¿æ¢3-4å¤„
  â—¦ 0åˆ†ï¼šé‡å¤ä½¿ç”¨åŸºç¡€è¯æ±‡
â€¢ 3.2 ç”¨è¯å‡†ç¡®æ€§ï¼ˆ3åˆ†ï¼‰
  â—¦ 3åˆ†ï¼šæ— ä¸­å¼è‹±è¯­ä¸”æ­é…ç²¾å‡†ï¼ˆ"make a decision"ï¼‰
  â—¦ 1åˆ†ï¼š1-2å¤„é”™è¯¯ï¼ˆè¯¯ç”¨"borrow"ä»£æ›¿"lend"ï¼‰
  â—¦ 0åˆ†ï¼šâ‰¥3å¤„æ­é…é”™è¯¯
â€¢ 3.3 é«˜çº§è¯æ±‡ï¼ˆ4åˆ†ï¼‰
  â—¦ 4åˆ†ï¼šC1+è¯æ±‡â‰¥3ä¸ªï¼ˆresilient, dilemmaï¼‰
  â—¦ 2åˆ†ï¼šä½¿ç”¨1-2ä¸ª
  â—¦ 0åˆ†ï¼šä»…åŸºç¡€è¯æ±‡
4. è¯­æ³•å‡†ç¡®æ€§ï¼ˆ15åˆ†ï¼‰
â€¢ 4.1 ä¸»è°“ä¸€è‡´ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šé›¶é”™è¯¯
  â—¦ 2åˆ†ï¼š1-2å¤„é”™è¯¯ï¼ˆ"She don't know"ï¼‰
  â—¦ 0åˆ†ï¼šâ‰¥3å¤„é”™è¯¯
â€¢ 4.2 æ—¶æ€æ­£ç¡®ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šå…¨æ–‡æ—¶æ€ä¸åŸæ–‡100%ä¸€è‡´
  â—¦ 2åˆ†ï¼š1-2å¤„æ—¶æ€è·³è·ƒï¼ˆè¿‡å»â†’ç°åœ¨æ—¶ï¼‰
  â—¦ 0åˆ†ï¼šâ‰¥3å¤„æ—¶æ€é”™è¯¯
â€¢ 4.3 å¥å­ç»“æ„ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šæ— ç²˜è¿å¥/ç‰‡æ®µå¥
  â—¦ 2åˆ†ï¼š1å¤„ç»“æ„é”™è¯¯ï¼ˆæ— è¿è¯é€—å·è¿æ¥ï¼‰
  â—¦ 0åˆ†ï¼šâ‰¥2å¤„ç»“æ„é”™è¯¯
5. å¥å¼å¤šæ ·æ€§ï¼ˆ10åˆ†ï¼‰
â€¢ 5.1 å¤åˆå¥å æ¯”ï¼ˆ4åˆ†ï¼‰
  â—¦ 4åˆ†ï¼šå¤åˆå¥â‰¥40%ï¼ˆå¦‚å®šè¯­ä»å¥"who..."ï¼‰
  â—¦ 2åˆ†ï¼š30-39%
  â—¦ 0åˆ†ï¼šï¼œ30%
â€¢ 5.2 ç‰¹æ®Šå¥å¼ï¼ˆ6åˆ†ï¼‰
  â—¦ 6åˆ†ï¼šä½¿ç”¨â‰¥3ç§ï¼ˆå€’è£…/å¼ºè°ƒ/ç‹¬ç«‹ä¸»æ ¼ï¼‰
  â—¦ 2åˆ†ï¼šä½¿ç”¨1-2ç§
  â—¦ 0åˆ†ï¼šæœªä½¿ç”¨
6. è¡”æ¥ä¸è¿è´¯æ€§ï¼ˆ10åˆ†ï¼‰
â€¢ 6.1 æ˜¾æ€§è¡”æ¥ï¼ˆ6åˆ†ï¼‰
  â—¦ 6åˆ†ï¼šè¿‡æ¸¡è¯ä½¿ç”¨â‰¥3æ¬¡ä¸”æ°å½“ï¼ˆhowever/meanwhileï¼‰
  â—¦ 3åˆ†ï¼šä½¿ç”¨1-2æ¬¡
  â—¦ 1åˆ†ï¼šæœªä½¿ç”¨æˆ–è¯¯ç”¨ï¼ˆç”¨"therefore"è¡¨è½¬æŠ˜ï¼‰
â€¢ 6.2 éšæ€§è¡”æ¥ï¼ˆ4åˆ†ï¼‰
  â—¦ 4åˆ†ï¼šä»£è¯æŒ‡ä»£100%æ¸…æ™°ï¼ˆ"they"æ˜ç¡®æŒ‡æ•‘æ´é˜Ÿï¼‰
  â—¦ 2åˆ†ï¼š1-2å¤„æŒ‡ä»£æ¨¡ç³Š
  â—¦ 0åˆ†ï¼šâ‰¥3å¤„æŒ‡ä»£æ··ä¹±
7. åˆ›æ–°æ€§ä¸é€»è¾‘æ€§ï¼ˆ10åˆ†ï¼‰
â€¢ 7.1 ç»†èŠ‚åˆ›æ–°ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šæ·»åŠ â‰¥2ä¸ªåˆç†æ–°å…ƒç´ ï¼ˆé”ˆæŒ‡å—é’ˆ/é‡æœå……é¥¥ï¼‰
  â—¦ 2åˆ†ï¼šæ·»åŠ 1ä¸ªæ–°å…ƒç´ 
  â—¦ 0åˆ†ï¼šæ— æ–°ç»†èŠ‚æˆ–è„±ç¦»é€»è¾‘
â€¢ 7.2 å› æœé€»è¾‘ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šäº‹ä»¶å› æœé“¾å®Œæ•´ï¼ˆå—ä¼¤â†’æ¶ˆæ¯’â†’æ¢å¤ï¼‰
  â—¦ 2åˆ†ï¼šå› æœåŸºæœ¬åˆç†ä½†ç¼ºæ­¥éª¤ï¼ˆç›´æ¥åŒ…æ‰æœªæ¸…æ´ï¼‰
  â—¦ 0åˆ†ï¼šå› æœæ–­è£‚ï¼ˆæœªè§£é‡Šå¦‚ä½•è·æ•‘ï¼‰
8. æ–‡ä½“ä¸äººç§°ä¸€è‡´æ€§ï¼ˆ10åˆ†ï¼‰
â€¢ 8.1 å™è¿°è§†è§’ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šä¸¥æ ¼ä¿æŒåŸæ–‡äººç§°ï¼ˆç¬¬ä¸€äººç§°å…¨ç¨‹"æˆ‘"ï¼‰
  â—¦ 3åˆ†ï¼š1-2å¤„äººç§°åç§»ï¼ˆæ··ç”¨"I"å’Œ"he"ï¼‰
  â—¦ 0åˆ†ï¼šå½»åº•æ”¹å˜è§†è§’
â€¢ 8.2 è¯­ä½“é£æ ¼ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼š100%ç¬¦åˆæ•…äº‹æ–‡ä½“ï¼ˆå¯¹è¯ç”¨å¼•å·ï¼Œæ— å­¦æœ¯è¯æ±‡ï¼‰
  â—¦ 3åˆ†ï¼š1-2å¤„é£æ ¼ä¸ç¬¦ï¼ˆç”¨"furthermore"æ›¿ä»£"then"ï¼‰
  â—¦ 0åˆ†ï¼šæ–‡ä½“æ··æ‚
9. è‹±è¯­æ–‡å­¦ç´ å…»ä¸æ•™å¸ˆä¸»è§‚è¯„ä»·ï¼ˆ10åˆ†ï¼‰
â€¢ 9.1 è‹±è¯­è¯­è¨€ç´ å…»ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šæ€»ä½“è¯»æ¥è‡ªç„¶æµç•…ï¼Œç§°å¾—ä¸Šæ˜¯åœ°é“çš„ native Englishï¼Œçœ‹ä¸å‡ºæ˜¯ä¸­å›½äººå†™çš„
  â—¦ 2åˆ†ï¼šæœ‰ä¸­æ–‡å¼è‹±è¯­çš„ç—•è¿¹
  â—¦ 0åˆ†ï¼šå®Œå…¨ä¸ç¬¦åˆè‹±è¯­è¯­è¨€ä¹ æƒ¯
â€¢ 9.2 æ•™å¸ˆä¸»è§‚è¯„ä»·ï¼ˆ5åˆ†ï¼‰
  â—¦ 5åˆ†ï¼šçœ‹èµ·æ¥å¾ˆèˆ’æœï¼ŒçœŸäººé˜…å·è€å¸ˆå¯èƒ½ä¼šå–œæ¬¢
  â—¦ 2åˆ†ï¼šçœŸäººé˜…å·è€å¸ˆå¯èƒ½ä¼šè§‰å¾—æœ‰ä¸è¶³ä¹‹å¤„
  â—¦ 0åˆ†ï¼šå®Œå…¨ä¸ç¬¦åˆè€å¸ˆçš„è¯„ä»·æ ‡å‡†

äºŒã€ä½œæ–‡é¢˜ç›®
${originalText}

ä¸‰ã€ä½œæ–‡å†…å®¹
${essayText}

å››ã€è¾“å‡ºæ ¼å¼
ç¤ºä¾‹æ ‡å‡†åŒ–JSONè¾“å‡ºï¼š
{
  "åˆ†é¡¹è¯„åˆ†": {
    "å†…å®¹ä¸åŸæ–‡èæ´½åº¦": {
      "æƒ…èŠ‚è¿è´¯æ€§": {
        "reason": "æ®µé¦–ç”¨'As the rain poured'è¡”æ¥åŸæ–‡æš´é›¨åœºæ™¯ï¼Œä½†ç¼ºä¹æ—¶é—´è¿‡æ¸¡è¯",
        "score": 2
      },
      "äººç‰©ä¸€è‡´æ€§": {
        "reason": "ä¸»è§’ä¿æŒå‹‡æ•¢è®¾å®šï¼Œä½†æœ‹å‹çªç„¶å†·æ¼ ï¼ˆåŸæ–‡è®¾å®šä¸ºçƒ­æƒ…ï¼‰",
        "score": 2
      },
      "ä¸»é¢˜å¥‘åˆåº¦": {
        "reason": "æ·±åŒ–'å‹‡æ°”'ä¸»é¢˜ï¼Œé€šè¿‡å…‹æœææƒ§æ¨åŠ¨æˆé•¿",
        "score": 2
      }
    },
    "æƒ…èŠ‚åˆç†æ€§ä¸å®Œæ•´æ€§": {
      "å†²çªè§£å†³": {
        "reason": "ç”¨å‰æ–‡'å“¨å­'å‘å‡ºæ±‚æ•‘ä¿¡å·ï¼Œä¼ç¬”å›æ”¶åˆç†",
        "score": 2
      },
      "ç¬¦åˆå¸¸è¯†": {
        "reason": "'æ¹¿æœ¨å¤´ç”Ÿç«'è¿åç‡ƒçƒ§å¸¸è¯†",
        "score": 1
      },
      "ç§¯æç»“å±€": {
        "reason": "ä¼ é€’å¸Œæœ›ä½†è·æ•‘è¿‡ç¨‹ä»“ä¿ƒ",
        "score": 2
      }
    },
    "è¯æ±‡ä¸°å¯Œæ€§": {
      "è¯æ±‡å¤šæ ·æ€§": {
        "reason": "åŒä¹‰è¯æ›¿æ¢4å¤„ï¼ˆshoutedâ†’screamed/criedï¼‰",
        "score": 3
      },
      "ç”¨è¯å‡†ç¡®æ€§": {
        "reason": "è¯¯ç”¨'receive the prize'åº”ä¸º'win the prize'",
        "score": 2
      },
      "é«˜çº§è¯æ±‡": {
        "reason": "ä½¿ç”¨'resilient'å’Œ'determination'",
        "score": 2
      }
    },
    // å…¶ä»–ç»´åº¦åŒç†ï¼Œä½ éœ€è¦æ ¹æ®å‰é¢æ‰€è¯´çš„ï¼Œæ¯ä¸€æ¡éƒ½è¦è¿›è¡Œè¯„åˆ†ã€‚
  }
}
${tonePrompt}
é‡è¦æé†’ï¼šä½ çš„è¾“å‡ºä»…åŒ…å«ã€JSONæ ¼å¼ã€‘ï¼Œä¸å…è®¸å‡ºç°å…¶ä»–å­—ç¬¦æˆ–æ³¨é‡Šã€‚å¯¹äºjsonæ ¼å¼ä¸­åŒå¼•å·é‡Œçš„å†…å®¹ï¼Œè¯·å‹¿å†æ¬¡ä½¿ç”¨åŒå¼•å·ï¼Œåªå…è®¸ä½¿ç”¨å•å¼•å·ã€‚`,
        },
      ],
      maxTokens: 4096,
      topP: 0.1,
    });

    // Iterate over the stream parts
    for await (const part of streamResult.fullStream) {
      // Check if the part is a text delta and has content
      if (part.type === 'text-delta' && part.textDelta) {
        const chunk = part.textDelta;
        // Write the chunk directly to the console's standard output
        process.stdout.write(chunk);
        // Append the chunk to the full response text
        fullResponseText += chunk;

        // --- Check for new category keys ---
        for (const category of SCORING_CATEGORIES) {
          // Check if category hasn't been reported yet AND appears in the text
          // We look for the category name enclosed in quotes followed by a colon
          // This is a heuristic and might need adjustment if AI format varies slightly
          const searchString = `"${category}":`;
          if (!reportedCategories.has(category) && fullResponseText.includes(searchString)) {
            // Send enqueue message for this category
            enqueue({ type: 'progress', message: `æ­£åœ¨è¯„åˆ†: ${category}` });
            // Mark this category as reported
            reportedCategories.add(category);
          }
        }
        // --- End check for new category keys ---
      }
      // You could potentially handle other part types here if needed
      // e.g., part.type === 'finish', part.type === 'error'
    }

    console.log("\n--- End of AI response stream ---"); // Add a newline and marker

    // Check if we received any response
    if (!fullResponseText) {
      throw new Error("AI response was empty.");
    }

    // Parse the accumulated JSON string
    const start = fullResponseText.indexOf('{');
    const end = fullResponseText.lastIndexOf('}');
    if (start === -1 || end === -1 || start >= end) {
      console.error("Invalid JSON structure received:", fullResponseText);
      throw new Error("Failed to find valid JSON object in AI response. Raw response logged.");
    }
    const jsonString = fullResponseText.substring(start, end + 1);

    let json: any;
    try {
      json = parse(jsonString); // Use best-effort parser
    } catch (parseError) {
      console.error("Failed to parse JSON:", parseError);
      console.error("Received JSON string:", jsonString);
      throw new Error(`Failed to parse AI response JSON: ${parseError}`);
    }

    // Check if the parsed JSON has the expected structure
    if (!json || typeof json !== 'object' || !json.åˆ†é¡¹è¯„åˆ†) {
      console.error("Parsed JSON missing expected 'åˆ†é¡¹è¯„åˆ†' key:", json);
      throw new Error("Parsed JSON does not have the expected structure ('åˆ†é¡¹è¯„åˆ†' key missing).");
    }

    // Calculate total score and format content
    let totalScore = 0;
    content += `# 3. è¯„åˆ†ç»†åˆ™\n`;
    // Ensure consistent order matching SCORING_CATEGORIES if possible, otherwise use the order from JSON
    const finalCategories = json.åˆ†é¡¹è¯„åˆ†; // Use the parsed JSON structure
    for (const key in finalCategories) { // Iterate through the keys from the actual JSON response
      if (Object.prototype.hasOwnProperty.call(finalCategories, key)) { // Ensure key is own property
        const section = finalCategories[key];
        // Format category header (e.g., make it bold markdown)
        content += `\n- **${key}**\n\n  `; // Add bold markdown and indent reasons
        let reasonContent = "";
        if (typeof section === 'object' && section !== null) { // Check if section is an object
          for (const subKey in section) {
            if (Object.prototype.hasOwnProperty.call(section, subKey)) { // Ensure subKey is own property
              const scoreValue = Number(section[subKey]?.score) || 0; // Ensure score is a number
              totalScore += scoreValue;
              // Combine reason and score for each sub-item if needed, or just reasons
              reasonContent += `${section[subKey]?.reason || 'N/A'}ï¼› `; // Add subkey/score detail
            }
          }
        } else {
          console.warn(`Section '${key}' is not an object or is null in the response.`);
          reasonContent = 'è¯„åˆ†æ•°æ®æ ¼å¼é”™è¯¯ï¼› ';
        }
        // Remove trailing semicolon and space, add period.
        content += reasonContent.trim().replace(/ï¼›$/, 'ã€‚') + '\n';
      }
    }

    // Convert to 25-point scale and round to one decimal place
    let score = Number((totalScore / 100 * 25).toFixed(1));

    // Fallback using regex - Keep this as a safety net
    if (isNaN(score) || (score === 0 && totalScore === 0 && fullResponseText.length > 10)) { // Added length check to avoid fallback on genuinely empty/failed responses
      console.warn("Initial score calculation resulted in 0 or NaN, attempting regex fallback...");
      const regex = /(\d+)\s*åˆ†/g;
      const matches = fullResponseText.match(regex);
      let fallbackSum = 0;
      if (matches) {
        fallbackSum = matches.reduce((acc, cur) => {
          const num = parseInt(cur, 10);
          return acc + (isNaN(num) ? 0 : num);
        }, 0);
        console.log(`Regex fallback found scores summing to: ${fallbackSum}`);
      } else {
        console.warn("Regex fallback found no score matches.");
      }
      if (fallbackSum > 0) {
        totalScore = fallbackSum;
        score = Number((totalScore / 100 * 25).toFixed(1));
        console.log(`Using fallback score: ${score}`);
      } else {
        console.warn("Fallback score is also 0 or failed. Score remains 0.");
        score = 0;
      }
    }

    // Ensure score is within 0-25 range and is a valid number
    score = Math.max(0, Math.min(25, isNaN(score) ? 0 : score));
    content += `\n## æ€»åˆ†\n${score}åˆ†`; // Use standard markdown for Total Score header

    console.log(`Final score calculated: ${score}`); // Log final score
    return { score, content };

  } catch (error) {
    console.error("Error generating score:", error);
    if (fullResponseText) {
      console.error("Partial AI response received before error:", fullResponseText);
    }
    enqueue({ type: 'error', message: 'ç”Ÿæˆè¯„åˆ†å¤±è´¥', error: String(error) });
    throw error;
  }
}

// Define the expected top-level keys in the JSON output for upgradation
const UPGRADATION_SECTIONS = [
  "è¯æ±‡",
  "è¯ç»„",
  "å¥å¼",
  "ç»†èŠ‚æå†™"
];

/**
 * Rewrites the user's essay continuation text to upgrade vocabulary, phrases, sentence structures, and detailed descriptions.
 * Streams the AI response (expected to be JSON), parses it, generates a Markdown summary, and sends progress updates.
 * Selects the AI model based on the 'model' parameter.
 * Note: The 'tone' parameter is included as requested but is not directly used
 * in the prompt content for the language enhancement suggestions.
 *
 * @param originalText The original text prompt (for context).
 * @param essayText The user's essay continuation text to upgrade.
 * @param tone The tone parameter (currently not used in the prompt for language enhancement suggestions).
 * @param model The model parameter ('llama', 'deepseek', 'qwen', 'glm', 'gpt4', or default).
 * @param enqueue Function to send progress updates via the stream.
 * @returns A Promise resolving to an object containing the parsed JSON and the generated Markdown content, or null if generation fails.
 */
export async function generateUpgradation(
  originalText: string,
  essayText: string,
  tone: string, // Added as requested, but not used in prompt content
  model: string, // Added as requested
  enqueue: EnqueueFunction
): Promise<{ json: any, markdownContent: string } | null> { // Changed return type
  enqueue({ type: 'progress', message: 'æ­£åœ¨åˆ†æå¹¶ç”Ÿæˆå‡æ ¼å»ºè®®...' });
  console.log("Initiating language upgradation...");

  let fullResponseText = ''; // Accumulator for the full AI response text
  const reportedSections = new Set<string>(); // Track sections already reported via enqueue
  let markdownContent = ''; // Accumulator for the Markdown content

  try {
    // Select the AI model based on the model parameter
    const aiModel = (
      model === 'llama' ? openai('@cf/meta/llama-4-scout-17b-16e-instruct') :
        model === 'deepseek' ? deepseek('deepseek-chat') :
          model === 'qwen' ? siliconflow('Qwen/Qwen3-8B') :
            model === 'glm' ? siliconflow('THUDM/GLM-Z1-9B-0414') :
              model === 'gpt4' ? siliconflow('gpt-3.5-turbo') :
                openai('@cf/qwen/qwen1.5-14b-chat-awq') // Default model
    );

    console.log("--- Streaming AI response for language upgradation ---");

    const streamResult = await streamText({
      model: aiModel,
      messages: [
        {
          role: 'system',
          content: `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„è‹±è¯­å†™ä½œåŠ©æ‰‹ï¼Œæ“…é•¿æå‡æ–‡ç« çš„è¯æ±‡ã€è¯ç»„ã€å¥å¼å’Œç»†èŠ‚æå†™æ°´å¹³ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®ç”¨æˆ·æä¾›çš„åŸæ–‡å’Œç»­å†™ï¼Œæ‰¾å‡ºç»­å†™ä¸­æœ‰å¾…æå‡çš„è¯æ±‡ã€è¯ç»„å’Œå¥å¼ï¼Œç»™å‡ºå‡æ ¼å»ºè®®ã€‚åŒæ—¶ç»™å‡ºè¯¥è¯æ±‡ã€è¯ç»„ã€å¥å¼æˆ–ç»†èŠ‚æå†™çš„ç›¸å…³è§£é‡Šå’Œä¾‹å¥ï¼ˆå¥å¼å’Œç»†èŠ‚æå†™éƒ¨åˆ†å¯èƒ½æ›´ä¾§é‡è¯´æ˜å’Œå‡æ ¼åçš„æ•ˆæœï¼‰ã€‚ä¸¥æ ¼ä¿æŒåŸæ–‡çš„æ•…äº‹æƒ…èŠ‚ã€äººç‰©è®¾å®šã€æ—¶æ€å’Œè¯­ä½“é£æ ¼ä¸å˜ã€‚ä¸è¦æ·»åŠ ã€åˆ é™¤æˆ–ä¿®æ”¹ä»»ä½•æƒ…èŠ‚æˆ–ä¿¡æ¯ã€‚ä½ çš„è¾“å‡ºåªèƒ½æ˜¯ä»¥JSONæ ¼å¼å±•ç°çš„å‡æ ¼å†…å®¹ï¼Œä¸å…è®¸åŒ…å«ä»»ä½•å…¶ä»–è¯´æ˜ã€æ³¨é‡Šæˆ–æ ¼å¼ã€‚

è¯·ä»”ç»†é˜…è¯»åŸæ–‡ï¼Œæ‰¾å‡ºæœ‰å¾…æå‡çš„è¯æ±‡ã€è¯ç»„ã€å¥å¼å’Œç»†èŠ‚æå†™ï¼Œç»™å‡ºå‡æ ¼å»ºè®®ã€‚æ¯ç±»ç»™å‡ºå°½å¯èƒ½å¤šçš„å‡æ ¼å»ºè®®ï¼ˆå¦‚æœåŸæ–‡ç»­å†™å†…å®¹è¶³å¤Ÿçš„è¯ï¼‰ã€‚ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š
{
    "è¯æ±‡": [
      { "åŸè¯": "energetic", "å‡æ ¼": "vigorous", "è‹±æ–‡é‡Šä¹‰": "full of energy, strength, and enthusiasm. It describes something done with a lot of force, effort, or intensity.", "ç®€æ˜ä¸­æ–‡é‡Šä¹‰": "<adj.> å……æ»¡æ´»åŠ›çš„ï¼›ç²¾åŠ›å……æ²›çš„", "è‹±æ–‡ä¾‹å¥": "Theodore Roosevelt was a strong and vigorous politician." },
      { "åŸè¯": "happy", "å‡æ ¼": "elated", "è‹±æ–‡é‡Šä¹‰": "in high spirits; jubilant or exultant.", "ç®€æ˜ä¸­æ–‡é‡Šä¹‰": "<adj.> å…´é«˜é‡‡çƒˆçš„ï¼›æ¬¢æ¬£é¼“èˆçš„", "è‹±æ–‡ä¾‹å¥": "She was elated at the prospect of a holiday." }
      // å…¶ä»–è¯æ±‡åŒç†
    ],
    "è¯ç»„": [
      { "åŸè¯ç»„": "walk quickly", "å‡æ ¼": "stride purposefully", "è‹±æ–‡é‡Šä¹‰": "to walk with long steps in a particular direction with a clear intention.", "ç®€æ˜ä¸­æ–‡é‡Šä¹‰": "å¤§æ­¥æµæ˜Ÿåœ°èµ°ï¼›åšå®šåœ°èµ°", "è‹±æ–‡ä¾‹å¥": "He watched her stride purposefully towards the manager's office." },
      { "åŸè¯ç»„": "think about", "å‡æ ¼": "contemplate", "è‹±æ–‡é‡Šä¹‰": "to think about something for a long time or in a serious way.", "ç®€æ˜ä¸­æ–‡é‡Šä¹‰": "æ²‰æ€ï¼›æ·±æ€ç†Ÿè™‘", "è‹±æ–‡ä¾‹å¥": "He sat on the beach contemplating the meaning of life." }
      // å…¶ä»–è¯ç»„åŒç†
    ],
    "å¥å¼": [
      { "åŸå¥": "He was so tired that he could not move.", "å‡æ ¼å¥": "So tired was he that he could not move.", "è¯´æ˜": "ä½¿ç”¨å€’è£…å¥å¼ï¼Œå¢å¼ºè¯­æ°”ã€‚", "è‹±æ–‡ä¾‹å¥": "So difficult was the exam that only 10% of the students passed." },
      { "åŸå¥": "The rain fell heavily.", "å‡æ ¼å¥": "Down came the heavy rain.", "è¯´æ˜": "ä½¿ç”¨å‰¯è¯å¼€å¤´çš„å€’è£…å¥ï¼Œä½¿æè¿°æ›´ç”ŸåŠ¨ã€‚", "è‹±æ–‡ä¾‹å¥": "Out of the house rushed the children." }
      // å…¶ä»–å¥å¼åŒç†
    ],
     "ç»†èŠ‚æå†™": [
      { "åŸæå†™": "The room was dark.", "å‡æ ¼æå†™": "The room was cloaked in a thick, oppressive darkness, where shadows seemed to writhe in the corners.", "è¯´æ˜": "å¢åŠ äº†æ¯”å–»å’Œæ›´å…·æ„Ÿ**å½©çš„è¯æ±‡ï¼Œå¢å¼ºäº†é»‘æš—çš„å‹æŠ‘æ„Ÿã€‚", "è‹±æ–‡ä¾‹å¥": "The ancient forest was cloaked in an eerie silence." },
      { "åŸæå†™": "She felt sad.", "å‡æ ¼æå†™": "A heavy cloak of sorrow settled upon her shoulders, weighing down her spirit with each passing moment.", "è¯´æ˜": "å°†æŠ½è±¡çš„æ‚²ä¼¤å…·è±¡åŒ–ï¼Œä½¿ç”¨æ¯”å–»ä½¿å…¶æ›´ç”ŸåŠ¨ã€‚", "è‹±æ–‡ä¾‹å¥": "A sense of dread settled upon him as he entered the old house." }
      // å…¶ä»–ç»†èŠ‚æå†™åŒç†
    ]
}

åŸæ–‡ï¼š
${originalText}

å¾…å‡æ ¼çš„ç»­å†™ï¼š
${essayText}

è¯·æä¾›å‡æ ¼åçš„JSONå†…å®¹ï¼š`,
        },
      ],
      maxTokens: 4096, // Adjust based on expected output length
      temperature: 0.5, // Allow some creativity in word choice, but not too much
      topP: 0.9, // Broaden sampling slightly for varied word choices
    });

    // Iterate over the stream parts
    for await (const part of streamResult.fullStream) {
      if (part.type === 'text-delta' && part.textDelta) {
        const chunk = part.textDelta;
        // Write the chunk directly to the console's standard output for debugging
        process.stdout.write(chunk);
        // Append the chunk to the full response text
        fullResponseText += chunk;

        // --- Check for new section keys ---
        for (const section of UPGRADATION_SECTIONS) {
          // Check if section hasn't been reported yet AND appears in the text
          // Look for the section name enclosed in quotes followed by a colon and potentially whitespace
          const searchString = `"${section}":`;
           if (!reportedSections.has(section) && fullResponseText.includes(searchString)) {
            // Send enqueue message for this section
            enqueue({ type: 'progress', message: `æ­£åœ¨ç”Ÿæˆ: ${section} å»ºè®®` });
            // Mark this section as reported
            reportedSections.add(section);
          }
        }
        // --- End check for new section keys ---
      }
    }

    console.log("\n--- End of AI response stream for language upgradation ---");

    // Check if we received any response
    if (!fullResponseText.trim()) {
      console.warn("AI response for language upgradation was empty or only whitespace.");
      enqueue({ type: 'error', message: 'æœªèƒ½ç”Ÿæˆå‡æ ¼å»ºè®®ï¼šAIè¿”å›ä¸ºç©º' });
      // Return null as the expected JSON was not received
      return null;
    }

    // Parse the accumulated JSON string
    const start = fullResponseText.indexOf('{');
    const end = fullResponseText.lastIndexOf('}');
    if (start === -1 || end === -1 || start >= end) {
      console.error("Invalid JSON structure received for upgradation:", fullResponseText);
      enqueue({ type: 'error', message: 'æœªèƒ½ç”Ÿæˆå‡æ ¼å»ºè®®ï¼šAIè¿”å›éJSONæ ¼å¼' });
      // Return null if JSON structure is invalid
      return null;
    }
    const jsonString = fullResponseText.substring(start, end + 1);

    let json: any;
    try {
      json = parse(jsonString); // Use best-effort parser
    } catch (parseError) {
      console.error("Failed to parse JSON for upgradation:", parseError);
      console.error("Received JSON string:", jsonString);
      enqueue({ type: 'error', message: `æœªèƒ½ç”Ÿæˆå‡æ ¼å»ºè®®ï¼šè§£æJSONå¤±è´¥: ${parseError}` });
      // Return null if JSON parsing fails
      return null;
    }

    // Optional: Add checks to ensure the parsed JSON has the expected top-level keys
    const hasExpectedKeys = UPGRADATION_SECTIONS.every(section => json && typeof json === 'object' && json[section] !== undefined);
    if (!hasExpectedKeys) {
         console.warn("Parsed JSON missing expected keys for upgradation:", json);
         // Log a warning but proceed with generating markdown from available data
         enqueue({ type: 'warning', message: 'å‡æ ¼å»ºè®®JSONç»“æ„ä¸å®Œæ•´æˆ–ç¼ºå°‘éƒ¨åˆ†ç±»åˆ«' });
    }

    // --- Generate Markdown Content ---
    markdownContent += '# è¯­è¨€å‡æ ¼å»ºè®®\n\n';

    for (const section of UPGRADATION_SECTIONS) {
        const items = json?.[section]; // Use optional chaining in case the section is missing

        if (Array.isArray(items) && items.length > 0) {
            markdownContent += `## ${section}å‡æ ¼\n\n`;

            items.forEach((item, index) => {
                markdownContent += `- **å»ºè®® ${index + 1}:**\n`;

                if (section === "è¯æ±‡") {
                    markdownContent += `  - **åŸè¯:** ${item.åŸè¯ || 'N/A'}\n`;
                    markdownContent += `  - **å‡æ ¼:** ${item.å‡æ ¼ || 'N/A'}\n`;
                    if (item.è‹±æ–‡é‡Šä¹‰) markdownContent += `  > **è‹±æ–‡é‡Šä¹‰:** ${item.è‹±æ–‡é‡Šä¹‰}\n`;
                    if (item.ç®€æ˜ä¸­æ–‡é‡Šä¹‰) markdownContent += `  > **ç®€æ˜ä¸­æ–‡é‡Šä¹‰:** ${item.ç®€æ˜ä¸­æ–‡é‡Šä¹‰}\n`;
                    if (item.è‹±æ–‡ä¾‹å¥) markdownContent += `  > **è‹±æ–‡ä¾‹å¥:** ${item.è‹±æ–‡ä¾‹å¥}\n`;
                } else if (section === "è¯ç»„") {
                    markdownContent += `  - **åŸè¯ç»„:** ${item.åŸè¯ç»„ || 'N/A'}\n`;
                    markdownContent += `  - **å‡æ ¼:** ${item.å‡æ ¼ || 'N/A'}\n`;
                     if (item.è‹±æ–‡é‡Šä¹‰) markdownContent += `  > **è‹±æ–‡é‡Šä¹‰:** ${item.è‹±æ–‡é‡Šä¹‰}\n`;
                    if (item.ç®€æ˜ä¸­æ–‡é‡Šä¹‰) markdownContent += `  > **ç®€æ˜ä¸­æ–‡é‡Šä¹‰:** ${item.ç®€æ˜ä¸­æ–‡é‡Šä¹‰}\n`;
                    if (item.è‹±æ–‡ä¾‹å¥) markdownContent += `  > **è‹±æ–‡ä¾‹å¥:** ${item.è‹±æ–‡ä¾‹å¥}\n`;
                } else if (section === "å¥å¼") {
                    markdownContent += `  - **åŸå¥:** ${item.åŸå¥ || 'N/A'}\n`;
                    markdownContent += `  - **å‡æ ¼å¥:** ${item.å‡æ ¼å¥ || 'N/A'}\n`;
                    if (item.è¯´æ˜) markdownContent += `  > **è¯´æ˜:** ${item.è¯´æ˜}\n`;
                    if (item.è‹±æ–‡ä¾‹å¥) markdownContent += `  > **è‹±æ–‡ä¾‹å¥:** ${item.è‹±æ–‡ä¾‹å¥}\n`;
                } else if (section === "ç»†èŠ‚æå†™") {
                     markdownContent += `  - **åŸæå†™:** ${item.åŸæå†™ || 'N/A'}\n`;
                    markdownContent += `  - **å‡æ ¼æå†™:** ${item.å‡æ ¼æå†™ || 'N/A'}\n`;
                    if (item.è¯´æ˜) markdownContent += `  > **è¯´æ˜:** ${item.è¯´æ˜}\n`;
                     // Note: Details section example didn't have English example, but adding it just in case AI provides it
                    if (item.è‹±æ–‡ä¾‹å¥) markdownContent += `  > **è‹±æ–‡ä¾‹å¥:** ${item.è‹±æ–‡ä¾‹å¥}\n`;
                }
                markdownContent += '\n'; // Add a newline after each item
            });
            markdownContent += '---\n\n'; // Add a horizontal rule after each section
        }
    }
    // --- End Generate Markdown Content ---


    console.log("Successfully generated and parsed upgradation suggestions.");
    // Return both the parsed JSON and the generated Markdown
    return { json, markdownContent };

  } catch (error) {
    console.error("Error generating language upgradation:", error);
    // Ensure an error message is sent via enqueue if not already sent by specific catches
    // Simple check to avoid duplicate error messages - might need more robust logic
    if (!fullResponseText.includes('"type":"error"')) {
       enqueue({ type: 'error', message: 'ç”Ÿæˆå‡æ ¼å»ºè®®å¤±è´¥', error: String(error) });
    }
    // Return null on error
    return null;
  }
}


// --- generateTitle and generateIcon remain unchanged ---

/**
 * Generates a title for the essay continuation based on the original text.
 * @param originalText The original text prompt.
 * @param enqueue Function to send progress updates via the stream.
 * @returns The generated title string.
 */
export async function generateTitle(
  originalText: string,
  enqueue: EnqueueFunction
): Promise<string> {
  enqueue({ type: 'progress', message: 'æ­£åœ¨ç”Ÿæˆæ ‡é¢˜...' });

  try {
    // Use a faster model for title generation
    const fastModel = openai('@cf/meta/llama-3.1-8b-instruct-fast'); // Assuming this model exists and is fast

    const { text: titleResponse } = await generateText({
      model: fastModel,
      messages: [
        {
          role: 'system',
          content: `ç”¨æˆ·å°†æä¾›ç»™ä½ ä¸€é“è¯»åç»­å†™é¢˜ï¼Œè¯·ä½ åˆ†æé¢˜ç›®å†…å®¹ï¼Œå¹¶æ€»ç»“å‡ºä¸€ä¸ªæ ‡é¢˜ï¼Œè¾“å‡ºæ—¶ä»…åŒ…å«ä¸€è¡Œè¯¥æ ‡é¢˜ï¼Œä¸å…è®¸å‡ºç°å…¶ä»–å­—ç¬¦æˆ–æ³¨é‡Šã€‚`,
        },
        {
          role: 'user',
          content: `è¯»åç»­å†™é¢˜ï¼š\n${originalText}`,
        }
      ],
      temperature: 0.5 // Allow some creativity for title
    });

    return titleResponse.trim(); // Return the generated title, trimmed

  } catch (error) {
    console.error("Error generating title:", error);
    enqueue({ type: 'error', message: 'ç”Ÿæˆæ ‡é¢˜å¤±è´¥', error: String(error) });
    throw error; // Re-throw
  }
}

/**
 * Generates an emoji icon for the essay continuation based on the original text.
 * @param originalText The original text prompt.
 * @param enqueue Function to send progress updates via the stream.
 * @returns The generated emoji icon string.
 */
export async function generateIcon(
  originalText: string,
  enqueue: EnqueueFunction
): Promise<string> {
  enqueue({ type: 'progress', message: 'æ­£åœ¨ç”Ÿæˆå›¾æ ‡...' });

  try {
    // Use a faster model for icon generation
    const fastModel = openai('@cf/meta/llama-3.1-8b-instruct-fast'); // Assuming this model exists and is fast

    const { text: icon } = await generateText({
      model: fastModel,
      messages: [
        {
          role: 'system',
          content: `ç”¨æˆ·å°†æä¾›ç»™ä½ ä¸€é“è¯»åç»­å†™é¢˜ï¼Œè¯·ä½ åˆ†æé¢˜ç›®å†…å®¹ï¼Œå¹¶è¾“å‡ºä¸€ä¸ªä½ è®¤ä¸ºä¸ä¹‹ç›¸å…³çš„emojiå­—ç¬¦ï¼ˆåªèƒ½ä¸€ä¸ªå­—ç¬¦ï¼Œä¾‹å¦‚ğŸ“ï¼‰ï¼Œå¹¶ä¸”åœ¨è¾“å‡ºæ—¶ä¸å…è®¸å‡ºç°å…¶ä»–å­—ç¬¦æˆ–æ³¨é‡Šã€‚`,
        },
        {
          role: 'user',
          content: `è¯»åç»­å†™é¢˜ï¼š\n${originalText}`,
        }
      ],
      temperature: 0.3 // Keep it focused
    });

    // Basic validation for a single character emoji
    const trimmedIcon = icon.trim();
    // Improved emoji check using unicode property escape and length check
    if (trimmedIcon && (trimmedIcon.length === 1 || /\p{Emoji}/u.test(trimmedIcon))) {
      // Return the first grapheme cluster if multiple emojis are returned accidentally
      const firstEmoji = [...trimmedIcon][0];
      return firstEmoji;
    } else {
      // If AI didn't return a single emoji, provide a default or log a warning
      console.warn(`AI did not return a single valid emoji for icon (received: '${icon}'), returning default.`);
      return "ğŸ“„"; // Default icon
    }

  } catch (error) {
    console.error("Error generating icon:", error);
    enqueue({ type: 'error', message: 'ç”Ÿæˆå›¾æ ‡å¤±è´¥', error: String(error) });
    // Return a default icon on error
    return "ğŸ“„";
  }
}
